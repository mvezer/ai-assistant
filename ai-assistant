#!/bin/bash

# Spinner.sh author: Tasos Latsas
# GitHub: https://github.com/tlatsas/bash-spinner
function _spinner() {
    # $1 start/stop
    #
    # on start: $2 display message
    # on stop : $2 process exit status
    #           $3 spinner function pid (supplied from stop_spinner)

    local on_success="DONE"
    local on_fail="FAIL"
    local white="\e[1;37m"
    local green="\e[1;32m"
    local red="\e[1;31m"
    local nc="\e[0m"

    case $1 in
        start)
            # calculate the column where spinner and status msg will be displayed
            # let column=$(tput cols)-${#2}-8
            let column=2
            # display message and position the cursor in $column column
            echo -ne ${2}
            printf "%${column}s"

            # start spinner
            i=1
            sp='\|/-'
            delay=${SPINNER_DELAY:-0.15}

            while :
            do
                printf "\b${sp:i++%${#sp}:1}"
                sleep $delay
            done
            ;;
        stop)
            if [[ -z ${3} ]]; then
                echo "spinner is not running.."
                exit 1
            fi

            kill $3 > /dev/null 2>&1

            # inform the user uppon success or failure
            echo -en "\b["
            if [[ $2 -eq 0 ]]; then
                echo -en "${green}${on_success}${nc}"
            else
                echo -en "${red}${on_fail}${nc}"
            fi
            echo -e "]"
            ;;
        *)
            echo "invalid argument, try {start/stop}"
            exit 1
            ;;
    esac
}

function start_spinner {
    # $1 : msg to display
    _spinner "start" "${1}" &
    # set global spinner pid
    _sp_pid=$!
    disown
}

function stop_spinner {
    # $1 : command exit status
    _spinner "stop" $1 $_sp_pid
    unset _sp_pid
}

function get_answer () {
  model="text-davinci-003"
  temperature=0
  max_tokens=1024
  prompt="$@"
  JSON_REQUEST=$( jq -n \
    --arg m "$model" \
    --arg p "$prompt" \
    --arg t "$temperature"  \
    --arg mt "$max_tokens" \
    '{model: $m, prompt: $p, temperature: $t|tonumber, max_tokens: $mt|tonumber}' )

  curl -s https://api.openai.com/v1/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d "$JSON_REQUEST"

}

while true; do
  read -p '>>> ' question
  printf "\n"
  start_spinner 'Retrieving answer...'
  answer=$( get_answer $question )
  stop_spinner $?
  echo $answer | jq -r '.choices[].text'
  printf "\n"
done
